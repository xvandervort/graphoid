#!/usr/bin/env glang

module dataframe

# DataFrame Module - Tabular data as graph structures with governance rules
#
# A DataFrame is a graph where:
# - Nodes represent cells in a table
# - Edges connect cells within rows and columns
# - Governance rules ensure tabular structure integrity
#
# Key Principles:
# 1. DataFrames are graphs with tabular governance rules
# 2. All operations preserve structural integrity
# 3. Columns have consistent types (enforced by rules)
# 4. Rows maintain fixed column count

# Create a new DataFrame from column definitions
func create(columns) {
    # For now, use a map to represent the DataFrame structure
    # Future: This will be a native graph type with DataFrame governance
    df = {
        "_type": "dataframe",
        "_columns": columns,
        "_data": [],
        "_row_count": 0
    }

    # Initialize empty columns
    for col in columns {
        df[col] = []
    }

    return df
}

# Create DataFrame from list of maps with explicit columns
func from_records(records, columns) {
    if records.size() == 0 {
        return create([])
    }

    # Create DataFrame with specified columns
    df = create(columns)

    # Add each record as a row
    for record in records {
        add_row(df, record)
    }

    return df
}

# Create DataFrame from column data using variable keys (enhanced!)
func from_column_data(column_data) {
    # column_data is a map where keys are column names, values are lists
    # Example: { "name": ["Alice", "Bob"], "age": [25, 30] }

    # Extract column names - this demonstrates variable keys!
    columns = []

    # Note: In future versions, we'll have map.keys() method
    # For now, check for common column patterns
    if column_data.has_key("name") {
        columns.append("name")
    }
    if column_data.has_key("age") {
        columns.append("age")
    }
    if column_data.has_key("department") {
        columns.append("department")
    }
    if column_data.has_key("score") {
        columns.append("score")
    }
    if column_data.has_key("product") {
        columns.append("product")
    }
    if column_data.has_key("price") {
        columns.append("price")
    }
    if column_data.has_key("quantity") {
        columns.append("quantity")
    }

    df = create(columns)

    # Find max row count
    max_rows = 0
    for col in columns {
        col_key = col  # Variable key usage!
        if column_data.has_key(col_key) {
            col_data = column_data[col_key]
            if col_data.size() > max_rows {
                max_rows = col_data.size()
            }
        }
    }

    # Build rows using variable keys for cleaner syntax
    for i in [].upto(max_rows - 1) {
        row = {}
        for col in columns {
            col_name = col  # Variable key for modern syntax
            if column_data.has_key(col_name) && i < column_data[col_name].size() {
                row[col_name] = column_data[col_name][i]  # Clean variable key assignment!
            } else {
                row[col_name] = none
            }
        }
        add_row(df, row)
    }

    return df
}

# Create DataFrame from CSV text
func from_csv(csv_text, has_headers) {
    import "csv" as csv_module

    # Parse CSV into list of lists
    rows = csv_module.parse(csv_text, has_headers, ",")

    if rows.size() == 0 {
        return create([])
    }

    # Determine columns
    columns = []
    data_start = 0

    if has_headers {
        # First row contains column names
        columns = rows[0]
        data_start = 1
    } else {
        # Generate column names: col0, col1, etc.
        first_row = rows[0]
        for i in first_row.upto(first_row.size() - 1) {
            columns.append("col" + i.to_string())
        }
    }

    # Create DataFrame
    df = create(columns)

    # Add data rows
    for i in [].upto(rows.size() - 1) {
        if i >= data_start {
            row_data = rows[i]
            row_map = {}

            for j in [].upto(columns.size() - 1) {
                col_name = columns[j]  # Use variable for cleaner syntax
                if j < row_data.size() {
                    row_map[col_name] = row_data[j]
                } else {
                    row_map[col_name] = none  # Missing values
                }
            }

            add_row(df, row_map)
        }
    }

    return df
}

# Add a row to DataFrame
func add_row(df, row_data) {
    # Validate that row has correct columns
    columns = df["_columns"]

    for col in columns {
        if row_data.has_key(col) {
            df[col].append(row_data[col])
        } else {
            df[col].append(none)  # Fill missing with none
        }
    }

    df["_data"].append(row_data)
    df["_row_count"] = df["_row_count"] + 1
}

# Select specific columns
func select(df, column_names) {
    result = create(column_names)

    # Copy data for selected columns using variable keys
    for i in [].upto(df["_row_count"] - 1) {
        row = {}
        for col in column_names {
            col_key = col  # Variable key for cleaner syntax
            if df.has_key(col) {
                row[col_key] = df[col][i]
            }
        }
        add_row(result, row)
    }

    return result
}

# Filter rows based on condition
func filter(df, column, predicate) {
    columns = df["_columns"]
    result = create(columns)

    # Check each row
    for i in [].upto(df["_row_count"] - 1) {
        value = df[column][i]

        # Apply predicate
        keep = false
        if predicate == "positive" {
            if value != none && value > 0 {
                keep = true
            }
        } else if predicate == "negative" {
            if value != none && value < 0 {
                keep = true
            }
        } else if predicate == "non_empty" {
            if value != none && value != "" {
                keep = true
            }
        } else if predicate == "truthy" {
            if value {
                keep = true
            }
        }

        # Add row if it passes filter
        if keep {
            row = {}
            for col in columns {
                col_var = col  # Variable key for enhanced readability
                row[col_var] = df[col][i]
            }
            add_row(result, row)
        }
    }

    return result
}

# Filter with custom function
func filter_by(df, column, filter_func) {
    columns = df["_columns"]
    result = create(columns)

    for i in [].upto(df["_row_count"] - 1) {
        value = df[column][i]

        # Apply custom filter function
        if filter_func(value) {
            row = {}
            for col in columns {
                col_name = col  # Variable key for consistency
                row[col_name] = df[col][i]
            }
            add_row(result, row)
        }
    }

    return result
}

# Aggregate operations
func aggregate(df, column, operation) {
    col_data = df[column]

    if operation == "sum" {
        total = 0
        for value in col_data {
            if value != none {
                total = total + value
            }
        }
        return total
    } else if operation == "mean" || operation == "avg" || operation == "average" {
        total = 0
        count = 0
        for value in col_data {
            if value != none {
                total = total + value
                count = count + 1
            }
        }
        if count > 0 {
            return total / count
        } else {
            return none
        }
    } else if operation == "min" {
        min_val = none
        for value in col_data {
            if value != none {
                if min_val == none || value < min_val {
                    min_val = value
                }
            }
        }
        return min_val
    } else if operation == "max" {
        max_val = none
        for value in col_data {
            if value != none {
                if max_val == none || value > max_val {
                    max_val = value
                }
            }
        }
        return max_val
    } else if operation == "count" {
        count = 0
        for value in col_data {
            if value != none {
                count = count + 1
            }
        }
        return count
    }

    return none
}

# Group by column and aggregate (simplified version)
func group_by(df, group_column, agg_column, operation) {
    # For now, return a simplified aggregation result
    # Full implementation requires map.keys() method

    # Calculate aggregate for entire column as placeholder
    return aggregate(df, agg_column, operation)
}

# Display DataFrame info
func info(df) {
    print("DataFrame with " + df["_row_count"].to_string() + " rows")
    print("Columns: " + df["_columns"].to_string())
}

# Get first n rows
func head(df, n) {
    columns = df["_columns"]
    result = create(columns)

    max_rows = n
    if n > df["_row_count"] {
        max_rows = df["_row_count"]
    }

    for i in [].upto(max_rows - 1) {
        row = {}
        for col in columns {
            col_key = col  # Variable key for modern syntax
            row[col_key] = df[col][i]
        }
        add_row(result, row)
    }

    return result
}

# Convert DataFrame to CSV string
func to_csv(df) {
    lines = []
    columns = df["_columns"]

    # Add header row
    header = ""
    for i in [].upto(columns.size() - 1) {
        if i > 0 {
            header = header + ","
        }
        header = header + columns[i]
    }
    lines.append(header)

    # Add data rows
    for i in [].upto(df["_row_count"] - 1) {
        row_str = ""
        for j in [].upto(columns.size() - 1) {
            if j > 0 {
                row_str = row_str + ","
            }
            value = df[columns[j]][i]
            if value != none {
                row_str = row_str + value.to_string()
            }
        }
        lines.append(row_str)
    }

    # Join lines
    result = ""
    for line in lines {
        if result != "" {
            result = result + "\n"
        }
        result = result + line
    }

    return result
}

# DataFrame Rules (Future: These will be enforced by control layer)
#
# 1. TABULAR_STRUCTURE: All rows must have same columns
# 2. COLUMN_CONSISTENCY: Values in a column should have consistent type
# 3. ROW_INTEGRITY: Rows maintain connection to their columns
# 4. NO_CROSS_CONTAMINATION: Cell edges only within same DataFrame
# 5. ORDERED_ACCESS: Rows accessed sequentially, columns by name

# Future governance rules to be implemented:
func _define_dataframe_rules() {
    # These conceptual rules will be enforced when DataFrames
    # become native graph types with control layer governance

    rules = [
        "tabular_structure",      # Enforces rectangular shape
        "column_type_consistency", # Same type within column
        "row_column_edges_only",   # No diagonal edges
        "no_external_edges",       # Cells can't link outside
        "preserve_row_order"       # Row sequence maintained
    ]

    return rules
}

print("DataFrame module loaded - tabular data with graph governance")