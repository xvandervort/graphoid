# Benchmarking Infrastructure for Glang
# Provides performance measurement and comparison tools
# Uses modern function parameter passing for flexible timing

import "time" as Time

# Simple timing measurement
func start_timer() {
    return Time.now()
}

func end_timer(start_time) {
    end_time = Time.now()
    duration = end_time.to_num() - start_time.to_num()
    return {
        "start_time": start_time.to_string(),
        "end_time": end_time.to_string(),
        "duration": duration
    }
}

# Measure operation using function parameter
func time_operation(operation, iterations) {
    if iterations <= 0 {
        iterations = 1
    }

    start_time = start_timer()

    for i in [].upto(iterations - 1) {
        operation()
    }

    timing = end_timer(start_time)
    avg_duration = timing["duration"] / iterations

    return {
        "iterations": iterations,
        "total_duration": timing["duration"],
        "average_duration": avg_duration,
        "operations_per_second": iterations / timing["duration"]
    }
}

# Predefined benchmark operations for testing (fixed size = 100)
func benchmark_list_append() {
    items = []
    for i in [].upto(99) {
        items.append(i)
    }
    return items.size()
}

func benchmark_list_generate() {
    nums = []
    result = nums.generate(1, 100, 1)
    return result.size()
}

func benchmark_list_map() {
    nums = []
    base = nums.upto(100)
    result = base.map("double")
    return result.size()
}

func benchmark_list_filter() {
    nums = []
    base = nums.upto(100)
    result = base.filter("even")
    return result.size()
}

# Format timing results for display
func format_timing(timing, operation_name) {
    output = "Benchmark Results for " + operation_name + ":\n"
    output = output + "Iterations: " + timing["iterations"].to_string() + "\n"
    output = output + "Total Duration: " + timing["total_duration"].to_string() + " seconds\n"
    output = output + "Average Duration: " + timing["average_duration"].to_string() + " seconds\n"
    output = output + "Operations/Second: " + timing["operations_per_second"].to_string()
    return output
}

# Quick performance test using the new function parameter approach
func quick_performance_test() {
    print("=== Quick Performance Test ===")

    append_timing = time_operation(benchmark_list_append, 10)
    print("List Append: " + append_timing["operations_per_second"].to_string() + " ops/sec")

    generate_timing = time_operation(benchmark_list_generate, 10)
    print("List Generate: " + generate_timing["operations_per_second"].to_string() + " ops/sec")

    map_timing = time_operation(benchmark_list_map, 10)
    print("List Map: " + map_timing["operations_per_second"].to_string() + " ops/sec")

    filter_timing = time_operation(benchmark_list_filter, 10)
    print("List Filter: " + filter_timing["operations_per_second"].to_string() + " ops/sec")

    return "Performance test complete"
}