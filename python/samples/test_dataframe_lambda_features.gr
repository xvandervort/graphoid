#!/usr/bin/env glang

# Comprehensive test of new lambda-powered DataFrame capabilities

load "stdlib/dataframe.gr"

print("=== Testing Enhanced DataFrame with Lambda Operations ===")

# Create sample employee data
employees = dataframe.from_records([
    { "name": "Alice Johnson", "age": 32, "salary": 75000, "department": "Engineering" },
    { "name": "Bob Smith", "age": 28, "salary": 65000, "department": "Engineering" },
    { "name": "Charlie Brown", "age": 45, "salary": 95000, "department": "Management" },
    { "name": "Diana Prince", "age": 29, "salary": 70000, "department": "Marketing" },
    { "name": "Eve Adams", "age": 35, "salary": 80000, "department": "Engineering" },
    { "name": "Frank Wilson", "age": 52, "salary": 120000, "department": "Management" }
], ["name", "age", "salary", "department"])

print("Original employee data:")
dataframe.print_df(employees)

print("\n=== 1. Column Transformations with Lambdas ===")

# Give everyone a 10% raise
salary_boost = dataframe.transform_column(employees, "salary", x => x * 1.10)
print("After 10% salary increase:")
dataframe.print_df(salary_boost)

# Normalize names to uppercase
name_normalized = dataframe.transform_column(employees, "name", x => x.upper())
print("\nNames in uppercase:")
dataframe.print_df(name_normalized)

print("\n=== 2. Advanced Filtering ===")

# Find high-performing employees (salary > 75000 and age < 40)
high_performers = dataframe.where(employees, row =>
    row["salary"] > 75000 and row["age"] < 40
)
print("High performers (salary > 75K, age < 40):")
dataframe.print_df(high_performers)

# Complex filtering with multiple conditions
senior_engineers = dataframe.filter_advanced(employees, [
    { "column": "department", "predicate": x => x == "Engineering" },
    { "column": "age", "predicate": x => x > 30 }
])
print("\nSenior engineers (Engineering + age > 30):")
dataframe.print_df(senior_engineers)

print("\n=== 3. Statistical Analysis ===")

# Compute salary statistics
salary_stats = dataframe.compute_stats(employees, "salary")
print("Salary statistics:")
print("  Count: " + salary_stats["count"].to_string())
print("  Mean: $" + salary_stats["mean"].to_string())
print("  Std Dev: $" + salary_stats["std"].to_string())
print("  Min: $" + salary_stats["min"].to_string())
print("  Max: $" + salary_stats["max"].to_string())

# Find salary outliers (more than 1.5 standard deviations from mean)
outliers = dataframe.find_outliers(employees, "salary", 1.5)
print("\nSalary outliers (>1.5 std dev):")
dataframe.print_df(outliers)

print("\n=== 4. Advanced Aggregations ===")

# Custom aggregation: average salary per department
dept_avg_salary = dataframe.group_by_advanced(employees, "department", [
    {
        "source_column": "salary",
        "function": x => x.sum() / x.size(),
        "result_column": "avg_salary"
    }
])
print("Average salary by department:")
dataframe.print_df(dept_avg_salary)

# Multiple aggregations per group
dept_summary = dataframe.group_by_advanced(employees, "department", [
    {
        "source_column": "salary",
        "function": x => x.sum() / x.size(),
        "result_column": "avg_salary"
    },
    {
        "source_column": "age",
        "function": x => x.sum() / x.size(),
        "result_column": "avg_age"
    },
    {
        "source_column": "name",
        "function": x => x.size(),
        "result_column": "employee_count"
    }
])
print("\nDepartment summary (avg salary, avg age, count):")
dataframe.print_df(dept_summary)

print("\n=== 5. Derived Columns ===")

# Add experience level based on age
with_experience = dataframe.add_column(employees, "experience_level", "age", age => {
    if age < 30 { return "Junior" }
    else if age < 40 { return "Mid-level" }
    else { return "Senior" }
})
print("With experience levels:")
dataframe.print_df(with_experience)

# Add bonus calculation (10% of salary for seniors, 5% for others)
with_bonus = dataframe.add_column(with_experience, "bonus", "salary", salary => {
    # Note: In a real implementation, we'd access the experience_level here
    # For now, using a simple salary-based calculation
    if salary > 90000 { return salary * 0.10 }
    else { return salary * 0.05 }
})
print("\nWith bonus calculations:")
dataframe.print_df(with_bonus)

print("\n=== 6. Data Pipeline ===")

# Chain multiple operations in a pipeline
pipeline_ops = [
    {
        "type": "filter",
        "predicate": row => row["age"] >= 30
    },
    {
        "type": "transform",
        "column": "salary",
        "function": x => x * 1.15  # 15% raise for mature employees
    },
    {
        "type": "add_column",
        "new_column": "tax_bracket",
        "source_column": "salary",
        "function": x => {
            if x < 70000 { return "Low" }
            else if x < 100000 { return "Medium" }
            else { return "High" }
        }
    }
]

processed = dataframe.pipeline(employees, pipeline_ops)
print("Processed through pipeline (age>=30, 15% raise, tax brackets):")
dataframe.print_df(processed)

print("\n=== 7. Custom Aggregation Functions ===")

# Custom aggregation: salary range (max - min) per department
dept_salary_range = dataframe.aggregate_by(employees, "salary", salaries =>
    salaries.max() - salaries.min()
)
print("Overall salary range: $" + dept_salary_range.to_string())

# Department-specific ranges using grouping
dept_ranges = dataframe.group_by_advanced(employees, "department", [
    {
        "source_column": "salary",
        "function": x => x.max() - x.min(),
        "result_column": "salary_range"
    }
])
print("\nSalary ranges by department:")
dataframe.print_df(dept_ranges)

print("\n=== 8. Data Validation & Cleaning ===")

# Test data with some invalid entries
test_data = dataframe.from_records([
    { "name": "Valid User", "age": 25, "email": "user@example.com" },
    { "name": "", "age": -5, "email": "invalid" },
    { "name": "Another User", "age": 30, "email": "valid@test.com" },
    { "name": "Bad Data", "age": 150, "email": "" }
], ["name", "age", "email"])

print("Test data with invalid entries:")
dataframe.print_df(test_data)

# Clean the data using validation rules
validation_rules = [
    { "column": "name", "rule": x => x != none and x.size() > 0 },
    { "column": "age", "rule": x => x != none and x > 0 and x < 120 },
    { "column": "email", "rule": x => x != none and x.contains("@") and x.size() > 3 }
]

clean_data = dataframe.clean_data(test_data, validation_rules)
print("\nAfter data cleaning:")
dataframe.print_df(clean_data)

print("\n=== All Lambda-Powered DataFrame Tests Completed! ===")
print("âœ… Column transformations with custom lambdas")
print("âœ… Advanced filtering with complex conditions")
print("âœ… Statistical analysis and outlier detection")
print("âœ… Custom aggregation functions")
print("âœ… Derived column calculations")
print("âœ… Data processing pipelines")
print("âœ… Data validation and cleaning")
print("\nðŸš€ DataFrames are now a complete data analysis platform!")