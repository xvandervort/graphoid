# Bitcoin Price Tracker - Enhanced with HTTP Module
# Uses the new HTTP client module for robust data fetching and error handling

import "http" as http
import "html_parser" as html
import "json" as json
import "network" as network
import "time" as time
import "io" as io

print("â‚¿ Bitcoin Price Tracker (HTTP Module Edition)")
print("============================================")
print("ğŸš€ Using advanced HTTP client for reliable price fetching")

# Configuration
string coinmarketcap_url = "https://coinmarketcap.com/currencies/bitcoin/"
string coingecko_api = "https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd"
string csv_file = "data/bitcoin_prices_http.csv"
string user_agent = "Glang-Bitcoin-Tracker/2.0"

# Create data directory if it doesn't exist
if io.is_dir("data") == false {
    io.make_dir("data")
    print("ğŸ“ Created data directory")
}

# Helper function to create standard headers
func create_headers() {
    headers = {}
    headers["User-Agent"] = user_agent
    headers["Accept"] = "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    headers["Accept-Language"] = "en-US,en;q=0.5"
    headers["Connection"] = "keep-alive"
    return headers
}

# Helper function to create API headers
func create_api_headers() {
    headers = {}
    headers["User-Agent"] = user_agent
    headers["Accept"] = "application/json"
    headers["Content-Type"] = "application/json"
    return headers
}

# Enhanced Bitcoin price extraction using HTTP and HTML parsing
func extract_bitcoin_price_html(html_content) {
    print("ğŸ” Parsing HTML content for Bitcoin price...")

    # Parse the HTML content
    elements = html.parse(html_content)
    print("âœ… Parsed HTML structure with " + elements.size().to_string() + " root elements")

    # Strategy 1: Look for elements containing price information
    price_elements = html.find_containing_text(elements, "Bitcoin")
    if price_elements.size() > 0 {
        print("ğŸ¯ Found " + price_elements.size().to_string() + " elements mentioning Bitcoin")

        for price_element in price_elements {
            element_info = html.get_element_info(price_element)
            text = element_info["text"]

            # Look for price pattern: $X,XXX.XX
            if text.contains("$") {
                price = extract_price_from_text(text)
                if price != "FAILED" {
                    return price
                }
            }
        }
    }

    # Strategy 2: Look for meta tags with price information
    meta_elements = html.find_by_tag(elements, "meta")
    print("ğŸ” Found " + meta_elements.size().to_string() + " meta elements")

    for meta_element in meta_elements {
        content_attr = html.get_attribute(meta_element, "content")
        name_attr = html.get_attribute(meta_element, "name")

        # Check if it's a description or price-related meta tag
        if content_attr.contains("Bitcoin") and content_attr.contains("$") {
            print("ğŸ’° Found price in meta content: " + content_attr)
            price = extract_price_from_text(content_attr)
            if price != "FAILED" {
                return price
            }
        }
    }

    # Strategy 3: Look for span/div elements with price classes
    price_containers = html.find_by_attribute(elements, "class")
    for container in price_containers {
        class_attr = html.get_attribute(container, "class")
        if class_attr.contains("price") or class_attr.contains("value") {
            element_info = html.get_element_info(container)
            text = element_info["text"]

            if text.contains("$") {
                price = extract_price_from_text(text)
                if price != "FAILED" {
                    return price
                }
            }
        }
    }

    print("âŒ Could not extract Bitcoin price from HTML structure")
    return "FAILED"
}

# Enhanced price extraction from text using string methods
func extract_price_from_text(text) {
    print("ğŸ”¤ Extracting price from: " + text.substring(0, 50) + "...")

    # Clean the text first
    clean_text = html.clean_text(text)

    # Look for patterns like "$123,456.78" or "$123456.78"
    if clean_text.contains("$") {
        # Find all dollar sign positions
        dollar_pos = clean_text.index_of("$")
        if dollar_pos >= 0 {
            # Extract text after dollar sign
            after_dollar = clean_text.substring(dollar_pos + 1)

            # Find the end of the price (first non-price character)
            price_end = 0
            while price_end < after_dollar.length() {
                char = after_dollar.substring(price_end, price_end + 1)
                # Price characters: digits, comma, period
                if char.contains("any", "digits") or char == "," or char == "." {
                    price_end = price_end + 1
                } else {
                    break
                }
            }

            if price_end > 0 {
                price = after_dollar.substring(0, price_end)
                print("ğŸ’° Extracted price: $" + price)
                return price
            }
        }
    }

    return "FAILED"
}

# Try CoinGecko API first (more reliable)
func fetch_bitcoin_price_api() {
    print("ğŸŒ Trying CoinGecko API...")

    response = http.get(coingecko_api, create_api_headers())

    if response["success"] {
        print("âœ… API response received")
        body = response["body"]

        # Parse JSON response
        if json.is_valid(body) {
            data = json.decode(body)
            if data.has_key("bitcoin") {
                bitcoin_data = data["bitcoin"]
                if bitcoin_data.has_key("usd") {
                    price = bitcoin_data["usd"].to_string()
                    print("ğŸ’° Bitcoin price from API: $" + price)
                    return { "price": price, "source": "CoinGecko API" }
                }
            }
        }
    }

    print("âŒ CoinGecko API failed")
    return { "price": "FAILED", "source": "CoinGecko API" }
}

# Enhanced web scraping with multiple data sources
func fetch_bitcoin_price_scraping() {
    print("ğŸŒ Fetching Bitcoin price from CoinMarketCap...")

    response = http.get(coinmarketcap_url, create_headers())

    if response["success"] {
        print("âœ… Downloaded " + response["body"].length().to_string() + " characters from CoinMarketCap")

        price = extract_bitcoin_price_html(response["body"])
        if price != "FAILED" {
            return { "price": price, "source": "CoinMarketCap" }
        }
    } else {
        print("âŒ CoinMarketCap request failed with status: " + response["status"].to_string())
    }

    print("âŒ Web scraping failed")
    return { "price": "FAILED", "source": "CoinMarketCap" }
}

# Multi-source Bitcoin price fetching with fallbacks
func fetch_bitcoin_price_enhanced() {
    print("ğŸš€ Starting multi-source Bitcoin price fetching...")

    # Check network availability first
    if network.is_network_available() == false {
        print("âŒ Network not available")
        return { "price": "FAILED", "source": "No Network" }
    }

    # Strategy 1: Try API first (most reliable)
    api_result = fetch_bitcoin_price_api()
    if api_result["price"] != "FAILED" {
        return api_result
    }

    print("âš ï¸ API failed, trying web scraping...")

    # Strategy 2: Fallback to web scraping
    scraping_result = fetch_bitcoin_price_scraping()
    if scraping_result["price"] != "FAILED" {
        return scraping_result
    }

    print("âŒ All price fetching methods failed")
    return { "price": "FAILED", "source": "All sources failed" }
}

# Enhanced CSV saving with metadata
func save_enhanced_csv(price_data, timestamp) {
    print("ğŸ’¾ Saving enhanced data to " + csv_file)

    # Check if file exists
    file_exists = io.exists(csv_file)

    if file_exists == false {
        # Create file with enhanced headers
        headers = "timestamp,price_usd,source,method,quality,response_time\n"
        io.write_file(csv_file, headers)
        print("ğŸ“ Created enhanced CSV file with metadata columns")
    }

    # Determine data quality
    quality = "high"
    if price_data["source"].contains("scraping") or price_data["source"].contains("CoinMarketCap") {
        quality = "medium"
    }
    if price_data["price"] == "FAILED" {
        quality = "failed"
    }

    # Calculate approximate response time (simplified)
    response_time = "< 5s"

    # Append enhanced data
    new_row = timestamp + "," + price_data["price"] + "," + price_data["source"] + "," + "http_module," + quality + "," + response_time + "\n"

    io.append_file(csv_file, new_row)
    print("âœ… Saved enhanced data: " + timestamp + " -> $" + price_data["price"] + " (" + price_data["source"] + ")")
}

# Enhanced statistics and analysis
func show_enhanced_statistics() {
    if io.exists(csv_file) {
        print("\nğŸ“Š Enhanced Bitcoin Price Analysis:")
        print("==================================")

        content = io.read_file(csv_file)
        lines = content.split("\n")

        # Skip header and count records
        records = 0
        successful = 0
        failed = 0
        latest_price = "N/A"
        latest_source = "N/A"

        i = 1  # Skip header
        while i < lines.size() {
            line = lines[i].trim()
            if line.length() > 0 {
                parts = line.split(",")
                if parts.size() >= 5 {
                    records = records + 1

                    price = parts[1]
                    source = parts[2]
                    quality = parts[4]

                    if quality == "failed" {
                        failed = failed + 1
                    } else {
                        successful = successful + 1
                        latest_price = price
                        latest_source = source
                    }
                }
            }
            i = i + 1
        }

        # Display statistics
        print("ğŸ“ˆ Total Records: " + records.to_string())
        print("âœ… Successful: " + successful.to_string())
        print("âŒ Failed: " + failed.to_string())

        if successful > 0 {
            success_rate = (successful * 100) / records
            print("ğŸ¯ Success Rate: " + success_rate.to_string() + "%")
            print("ğŸ’° Latest Price: $" + latest_price)
            print("ğŸ“Š Latest Source: " + latest_source)
        }

        # Show recent entries
        print("\nğŸ“‹ Recent Entries:")
        start = lines.size() - 6  # Show last 5 entries
        if start < 1 { start = 1 }

        j = start
        while j < lines.size() {
            line = lines[j].trim()
            if line.length() > 0 {
                parts = line.split(",")
                if parts.size() >= 3 {
                    print("  " + parts[0] + " -> $" + parts[1] + " (" + parts[2] + ")")
                }
            }
            j = j + 1
        }
    }
}

# Main execution with enhanced error handling
print("ğŸš€ Starting enhanced Bitcoin price tracking...")
print("âœ¨ Features: HTTP client, API + Web scraping, Error handling, Multi-source")

price_data = fetch_bitcoin_price_enhanced()

if price_data["price"] != "FAILED" {
    print("\nâ° Getting timestamp...")
    timestamp = time.now().to_string()

    print("ğŸ’¾ Saving enhanced data...")
    save_enhanced_csv(price_data, timestamp)

    print("\nğŸ“‹ Summary:")
    print("================")
    print("  ğŸ’° Bitcoin Price: $" + price_data["price"])
    print("  ğŸ“Š Data Source: " + price_data["source"])
    print("  â° Timestamp: " + timestamp)
    print("  ğŸ“ File: " + csv_file)
    print("  ğŸ”§ Method: HTTP Module + Multi-source")

    show_enhanced_statistics()

    print("\nâœ¨ Enhanced Bitcoin tracking completed successfully!")
    print("ğŸ” Using HTTP module with API + web scraping fallback")
    print("ğŸ“ˆ Run regularly to build comprehensive price history")

} else {
    print("\nâŒ Enhanced Bitcoin tracking failed")
    print("  ğŸ“Š All extraction methods unsuccessful")
    print("  ğŸŒ Check internet connection and try again")
    print("  ğŸ”§ Error details: " + price_data["source"])

    # Still save the failed attempt for analysis
    timestamp = time.now().to_string()
    save_enhanced_csv(price_data, timestamp)
}

print("\nğŸ”— Primary data source: " + coingecko_api)
print("ğŸ”— Fallback source: " + coinmarketcap_url)
print("ğŸ“ Enhanced data file: " + csv_file)
print("âš¡ Powered by Glang HTTP client module")